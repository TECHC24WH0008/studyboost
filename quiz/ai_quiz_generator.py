import openai
import json
import re
import requests
from django.conf import settings
from datetime import datetime, date
import yt_dlp
import tempfile
import os

class AIQuizGenerator:
    def __init__(self):
        # OpenAI APIè¨­å®š
        api_key = getattr(settings, 'OPENAI_API_KEY', None)
        
        print(f"ğŸ” ãƒ‡ãƒãƒƒã‚°: OpenAI API Key = {api_key[:20] + '...' if api_key else 'None'}")
        
        if api_key and api_key.startswith('sk-'):
            try:
                import openai
                self.openai_client = openai.OpenAI(api_key=api_key)
                
                # APIã‚­ãƒ¼ã®æœ‰åŠ¹æ€§ã‚’ãƒ†ã‚¹ãƒˆ
                try:
                    test_response = self.openai_client.models.list()
                    self.openai_available = True
                    print("âœ… OpenAI APIæ¥ç¶šãƒ†ã‚¹ãƒˆæˆåŠŸ")
                except Exception as test_error:
                    print(f"âŒ OpenAI APIæ¥ç¶šãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {test_error}")
                    self.openai_available = False
                
            except Exception as e:
                print(f"âŒ OpenAI APIåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
                self.openai_client = None
                self.openai_available = False
        else:
            self.openai_client = None
            self.openai_available = False
            print("âš ï¸ OpenAI API Keyæœªè¨­å®šã¾ãŸã¯ç„¡åŠ¹")
        
        # Hugging Faceè¨­å®š
        self.huggingface_api_key = getattr(settings, 'HUGGINGFACE_API_KEY', None)
        
        # YouTube APIè¨­å®š
        self.youtube_api_key = getattr(settings, 'YOUTUBE_API_KEY', None)
        
        print(f"ğŸ¤– AIç”Ÿæˆã‚ªãƒ—ã‚·ãƒ§ãƒ³:")
        print(f"  - OpenAI: {'âœ…' if self.openai_available else 'âŒ'}")
        print(f"  - Hugging Face API: {'âœ…' if self.huggingface_api_key else 'âŒ'}")
        print(f"  - YouTube API: {'âœ…' if self.youtube_api_key else 'âŒ'}")
        print(f"  - WhisperéŸ³å£°å‡¦ç†: {'âœ…' if self.openai_available else 'âŒ'}")

        # Whisperè¨­å®š
        self.whisper_settings = {
            'model': 'whisper-1',  # OpenAI Whisper API
            'language': 'ja',      # æ—¥æœ¬èª
            'response_format': 'text',
            'temperature': 0.0
        }
        
        # è¦ç´„è¨­å®š
        self.summary_settings = {
            'max_transcript_length': 8000,  # ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆæœ€å¤§é•·
            'summary_max_tokens': 1000,     # è¦ç´„æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
            'chunk_size': 3000,             # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã‚µã‚¤ã‚º
            'overlap_size': 200             # ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã‚µã‚¤ã‚º
        }
        
        # ç°¡ç´ åŒ–ã•ã‚ŒãŸã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š
        self.timeout_settings = {
            'openai_timeout': 30,
            'huggingface_timeout': 20,
            'total_timeout': 60,
            'fallback_timeout': 5
        }
        
        print(f"â±ï¸ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š:")
        print(f"  - OpenAI: {self.timeout_settings['openai_timeout']}ç§’")
        print(f"  - Hugging Face: {self.timeout_settings['huggingface_timeout']}ç§’")

        # ãƒ‡ãƒãƒƒã‚°è¨­å®š
        self.debug_settings = {
            'force_fallback': False,
            'force_ai_failure': False,
            'show_generation_process': True,
            'test_mode': False
        }

    def detect_content_type(self, title):
        """ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š"""
        title_lower = title.lower()
        
        content_patterns = {
            'math': ['ç®—æ•°', 'æ•°å­¦', 'è¨ˆç®—', 'æ–¹ç¨‹å¼', 'é–¢æ•°', 'å›³å½¢', 'ç¢ºç‡', 'çµ±è¨ˆ', 'ã¾ã„ã«ã¡ç®—æ•°'],
            'geography': ['åœ°ç†', 'éƒ½é“åºœçœŒ', 'çœŒåºæ‰€åœ¨åœ°', 'åœ°å›³', 'å›½', 'é¦–éƒ½', 'å±±', 'å·', 'æµ·', 'æ—¥æœ¬åœ°ç†'],
            'history': ['æ­´å²', 'æˆ¦å›½', 'æ±Ÿæˆ¸', 'æ˜æ²»', 'æ˜­å’Œ', 'å¹³æˆ', 'å¹´å·', 'æ­¦å°†', 'å¤©çš‡', 'æ™‚ä»£'],
            'science': ['ç§‘å­¦', 'åŒ–å­¦', 'ç‰©ç†', 'ç”Ÿç‰©', 'å®Ÿé¨“', 'å…ƒç´ ', 'åŒ–åˆç‰©', 'DNA'],
            'language': ['è‹±èª', 'å›½èª', 'æ¼¢å­—', 'æ–‡æ³•', 'å˜èª', 'ç™ºéŸ³', 'TOEIC', 'è‹±æ¤œ'],
            'programming': ['ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°', 'Python', 'JavaScript', 'HTML', 'CSS', 'ã‚³ãƒ¼ãƒ‰']
        }
        
        for content_type, keywords in content_patterns.items():
            if any(keyword in title_lower for keyword in keywords):
                return content_type
        
        return 'general'

    def calculate_age_from_birthdate(self, birth_date):
        """ç”Ÿå¹´æœˆæ—¥ã‹ã‚‰å¹´é½¢ã‚’è¨ˆç®—"""
        try:
            if isinstance(birth_date, str):
                birth_date = datetime.strptime(birth_date, '%Y-%m-%d').date()
            elif isinstance(birth_date, datetime):
                birth_date = birth_date.date()
            
            today = date.today()
            age = today.year - birth_date.year - ((today.month, today.day) < (birth_date.month, birth_date.day))
            return age
        except Exception as e:
            print(f"âŒ å¹´é½¢è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def determine_age_group_from_user(self, user):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‹ã‚‰å¹´é½¢ã‚°ãƒ«ãƒ¼ãƒ—ã‚’åˆ¤å®šï¼ˆä¿®æ­£ç‰ˆï¼‰"""
        try:
            # UserProfileã‹ã‚‰ç”Ÿå¹´æœˆæ—¥ã‚’å–å¾—
            if hasattr(user, 'userprofile'):
                profile = user.userprofile
                age_group = profile.get_age_group()
                age = profile.get_age()
                
                if age_group and age:
                    print(f"ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼å®Ÿå¹´é½¢: {age}æ­³ â†’ ã‚°ãƒ«ãƒ¼ãƒ—: {age_group}")
                    return age_group
            
            print("â„¹ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼å¹´é½¢æƒ…å ±ãªã— - ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰åˆ¤å®š")
            return None
            
        except Exception as e:
            print(f"âŒ ãƒ¦ãƒ¼ã‚¶ãƒ¼å¹´é½¢åˆ¤å®šã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def detect_age_group(self, video_title, user=None):
        """å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‹ã‚‰å¯¾è±¡å¹´é½¢ã‚’åˆ¤å®šï¼ˆå¼·åŒ–ç‰ˆï¼‰"""
        
        # 1. ã¾ãšãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å®Ÿå¹´é½¢ã‹ã‚‰åˆ¤å®š
        user_age_group = self.determine_age_group_from_user(user) if user else None
        if user_age_group:
            print(f"ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼å®Ÿå¹´é½¢ã«ã‚ˆã‚‹åˆ¤å®š: {user_age_group}")
            return user_age_group
        
        # 2. å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰åˆ¤å®šï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³å¼·åŒ–ï¼‰
        title_lower = video_title.lower()
        
        age_patterns = {
            'elementary_low': [  # å°å­¦1-3å¹´ç”Ÿ
                'å°å­¦1å¹´', 'å°å­¦2å¹´', 'å°å­¦3å¹´', '1å¹´ç”Ÿ', '2å¹´ç”Ÿ', '3å¹´ç”Ÿ',
                'ã²ã‚‰ãŒãª', 'ã‹ãŸã‹ãª', 'ãŸã—ã–ã‚“', 'ã²ãã–ã‚“', 
                'æ™‚è¨ˆ', 'ã‹ãš', '10ã¾ã§', 'ï¼‘ï¼ã¾ã§', '100ã¾ã§', 'ï¼‘ï¼ï¼ã¾ã§',
                'ç°¡å˜', 'ã‚„ã•ã—ã„', 'ã¯ã˜ã‚ã¦', 'åŸºæœ¬',
                'å°å­¦æ ¡ä½å­¦å¹´', 'å°å­¦ç”Ÿä½å­¦å¹´', 'å°å­¦ç”Ÿ1-3å¹´', 
                'å°ï¼‘', 'å°ï¼’', 'å°ï¼“', 'ä½å­¦å¹´'
            ],
            'elementary_mid': [  # å°å­¦4-6å¹´ç”Ÿ
                'å°å­¦4å¹´', 'å°å­¦5å¹´', 'å°å­¦6å¹´', '4å¹´ç”Ÿ', '5å¹´ç”Ÿ', '6å¹´ç”Ÿ',
                'å°ï¼”', 'å°ï¼•', 'å°ï¼–', 'å°å­¦æ ¡é«˜å­¦å¹´', 'å°å­¦ç”Ÿé«˜å­¦å¹´',
                'åˆ†æ•°', 'ã‚ã‚Šç®—', 'é¢ç©', 'ä½“ç©', 'å›³å½¢', 'å‰²ã‚Šç®—',
                'é«˜å­¦å¹´', 'å¿œç”¨', 'ç™ºå±•'
            ],
            'junior_high': [  # ä¸­å­¦ç”Ÿ
                'ä¸­å­¦', 'ä¸­ï¼‘', 'ä¸­ï¼’', 'ä¸­ï¼“', 'ä¸­å­¦ç”Ÿ', 
                'ä¸­å­¦1å¹´', 'ä¸­å­¦2å¹´', 'ä¸­å­¦3å¹´',
                'æ–¹ç¨‹å¼', 'é–¢æ•°', 'è¨¼æ˜', 'ç†ç§‘', 'ç¤¾ä¼š', 'è‹±èª',
                'ä¸­å­¦æ ¡', 'è¨¼æ˜å•é¡Œ', 'é€£ç«‹æ–¹ç¨‹å¼'
            ],
            'high_school': [  # é«˜æ ¡ç”Ÿ
                'é«˜æ ¡', 'é«˜ï¼‘', 'é«˜ï¼’', 'é«˜ï¼“', 'é«˜æ ¡ç”Ÿ', 
                'é«˜æ ¡1å¹´', 'é«˜æ ¡2å¹´', 'é«˜æ ¡3å¹´',
                'å¾®åˆ†', 'ç©åˆ†', 'åŒ–å­¦', 'ç‰©ç†', 'ç”Ÿç‰©', 
                'ä¸–ç•Œå²', 'æ—¥æœ¬å²', 'é«˜ç­‰å­¦æ ¡', 'å¤§å­¦å—é¨“'
            ]
        }
        
        # å„ªå…ˆåº¦é †ã§åˆ¤å®šï¼ˆã‚ˆã‚Šå…·ä½“çš„ãªã‚‚ã®ã‹ã‚‰ï¼‰
        for age_group, keywords in age_patterns.items():
            if any(keyword in title_lower for keyword in keywords):
                print(f"ğŸ“‹ ã‚¿ã‚¤ãƒˆãƒ«ã«ã‚ˆã‚‹å¹´é½¢åˆ¤å®š: {age_group}")
                return age_group
        
        print("ğŸ“‹ å¹´é½¢åˆ¤å®š: general")
        return 'general'

    def generate_quiz(self, video_id, user=None, force_fallback=False):
        """å‹•ç”»IDã‹ã‚‰ã‚¯ã‚¤ã‚ºã‚’è‡ªå‹•ç”Ÿæˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç¢ºèªå¯¾å¿œç‰ˆï¼‰"""
        try:
            # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¼·åˆ¶å®Ÿè¡Œ
            if force_fallback or self.debug_settings.get('force_fallback', False):
                print("ğŸ”§ ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”Ÿæˆã‚’å¼·åˆ¶å®Ÿè¡Œ")
                return self.execute_fallback_generation(video_id, user)
            
            # ä¿®æ­£: æ­£ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            from django.apps import apps
            
            try:
                # LearningVideoãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
                LearningVideo = apps.get_model('playlist', 'LearningVideo')
                video = LearningVideo.objects.get(id=video_id)
                video_title = video.title
                youtube_video_id = getattr(video, 'youtube_video_id', None)
                
                print(f"ğŸ¤– AIã‚¯ã‚¤ã‚ºç”Ÿæˆé–‹å§‹: ID={video_id}, ã‚¿ã‚¤ãƒˆãƒ«={video_title}")
                
            except LearningVideo.DoesNotExist:
                print(f"âŒ å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: ID={video_id}")
                return self.generate_fallback_quiz("å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            except Exception as model_error:
                print(f"âŒ ãƒ¢ãƒ‡ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼: {model_error}")
                return self.generate_fallback_quiz("ãƒ¢ãƒ‡ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼")
            
            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æ
            content_type = self.detect_content_type(video_title)
            age_group = self.detect_age_group(video_title, user)
            
            print(f"ğŸ“‹ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—: {content_type}")
            print(f"ğŸ‘¶ å¯¾è±¡å¹´é½¢ã‚°ãƒ«ãƒ¼ãƒ—: {age_group}")
            
            # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: AIç”Ÿæˆã‚’å¼·åˆ¶å¤±æ•—
            if self.debug_settings.get('force_ai_failure', False):
                print("ğŸ”§ ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: AIç”Ÿæˆã‚’å¼·åˆ¶å¤±æ•—")
                return self.execute_fallback_generation(video_id, user)
            
            # æ®µéšçš„AIç”Ÿæˆï¼ˆåŒæœŸç‰ˆï¼‰
            ai_result = self.try_ai_generation_sync(video_title, content_type, age_group)
            if ai_result and ai_result.get('questions'):
                print(f"âœ… AIç”ŸæˆæˆåŠŸ: {len(ai_result['questions'])}å•")
                return ai_result
            
            # AIç”Ÿæˆå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
            print("ğŸ”„ AIç”Ÿæˆå¤±æ•— - ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”Ÿæˆã‚’å®Ÿè¡Œ")
            return self.execute_fallback_generation(video_id, user)
        
        except Exception as e:
            print(f"âŒ ã‚¯ã‚¤ã‚ºç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return self.execute_fallback_generation(video_id, user, error_message=str(e))

    def execute_fallback_generation(self, video_id, user=None, error_message=None):
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”Ÿæˆã®å®Ÿè¡Œ"""
        try:
            from django.apps import apps
            LearningVideo = apps.get_model('playlist', 'LearningVideo')
            video = LearningVideo.objects.get(id=video_id)
            
            content_type = self.detect_content_type(video.title)
            age_group = self.detect_age_group(video.title, user)
            
            print(f"ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”Ÿæˆå®Ÿè¡Œ:")
            print(f"  - å‹•ç”»: {video.title}")
            print(f"  - ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—: {content_type}")
            print(f"  - å¹´é½¢ã‚°ãƒ«ãƒ¼ãƒ—: {age_group}")
            print(f"  - ã‚¨ãƒ©ãƒ¼ç†ç”±: {error_message or 'ä¸æ˜'}")
            
            # å¹´é½¢å¯¾å¿œãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”Ÿæˆ
            fallback_result = self.generate_age_specific_quiz(
                video.title, content_type, age_group, None
            )
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æƒ…å ±ã‚’è¿½åŠ 
            if fallback_result:
                fallback_result['generation_method'] = 'fallback'
                fallback_result['fallback_reason'] = error_message or 'AIç”Ÿæˆå¤±æ•—'
                fallback_result['content_analysis'] = {
                    'content_type': content_type,
                    'age_group': age_group,
                    'video_title': video.title
                }
                
                print(f"âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”ŸæˆæˆåŠŸ: {len(fallback_result.get('questions', []))}å•")
                return fallback_result
            
            # æœ€å¾Œã®æ‰‹æ®µ: ç·Šæ€¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return self.generate_emergency_fallback_quiz(video.title)
            
        except Exception as e:
            print(f"âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return self.generate_emergency_fallback_quiz(video.title)

    def generate_emergency_fallback_quiz(self, video_title):
        """ç·Šæ€¥æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¯ã‚¤ã‚ºï¼ˆå¿…ãšæˆåŠŸã™ã‚‹ï¼‰"""
        print("ğŸš¨ ç·Šæ€¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¯ã‚¤ã‚ºç”Ÿæˆ")
        
        return {
            "quiz_type": "emergency_fallback",
            "generation_method": "emergency",
            "content_type": "general",
            "age_group": "general",
            "video_title": video_title,
            "questions": [
                {
                    "question": f"ã€Œ{video_title}ã€ã®ã‚ˆã†ãªå‹•ç”»ã‚’å­¦ç¿’ã™ã‚‹éš›ã®åŸºæœ¬çš„ãªå¿ƒæ§‹ãˆã¯ï¼Ÿ",
                    "options": [
                        "ãªãŒã‚‰è¦‹ã§æ°—è»½ã«è¦–è´ã™ã‚‹",
                        "é›†ä¸­ã—ã¦å†…å®¹ã‚’ç†è§£ã—ã‚ˆã†ã¨ã™ã‚‹",
                        "é€Ÿåº¦ã‚’ä¸Šã’ã¦çŸ­æ™‚é–“ã§çµ‚ã‚ã‚‰ã›ã‚‹",
                        "éŸ³ã ã‘èã„ã¦ä»–ã®ä½œæ¥­ã‚’ã™ã‚‹"
                    ],
                    "correct": 2,
                    "explanation": "å­¦ç¿’å‹•ç”»ã¯é›†ä¸­ã—ã¦è¦–è´ã—ã€å†…å®¹ã‚’ã—ã£ã‹ã‚Šç†è§£ã™ã‚‹ã“ã¨ãŒæœ€ã‚‚é‡è¦ã§ã™ã€‚"
                },
                {
                    "question": "å‹•ç”»å­¦ç¿’ã§é‡è¦ãªã€Œã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã€ã¨ã¯ï¼Ÿ",
                    "options": [
                        "å—å‹•çš„ã«å‹•ç”»ã‚’è¦‹ã‚‹ã“ã¨",
                        "èƒ½å‹•çš„ã«è€ƒãˆãªãŒã‚‰å­¦ç¿’ã™ã‚‹ã“ã¨",
                        "å‹•ç”»ã‚’ç¹°ã‚Šè¿”ã—è¦‹ã‚‹ã“ã¨",
                        "ãƒãƒ¼ãƒˆã‚’å–ã‚‰ãšã«è¦‹ã‚‹ã“ã¨"
                    ],
                    "correct": 2,
                    "explanation": "ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ã¯ã€å—ã‘èº«ã§ã¯ãªãèƒ½å‹•çš„ã«è€ƒãˆã€å‚åŠ ã™ã‚‹å­¦ç¿’æ–¹æ³•ã§ã™ã€‚"
                },
                {
                    "question": "å­¦ç¿’åŠ¹æœã‚’é«˜ã‚ã‚‹ãŸã‚ã«å‹•ç”»è¦–è´å¾Œã«ã™ã¹ãã“ã¨ã¯ï¼Ÿ",
                    "options": [
                        "ã™ãã«æ¬¡ã®å‹•ç”»ã‚’è¦‹ã‚‹",
                        "å†…å®¹ã‚’æŒ¯ã‚Šè¿”ã‚Šã€ã¾ã¨ã‚ã‚‹",
                        "å¿˜ã‚Œã‚‹ã¾ã§æ”¾ç½®ã™ã‚‹",
                        "æ„Ÿæƒ³ã ã‘æ›¸ã"
                    ],
                    "correct": 2,
                    "explanation": "å‹•ç”»è¦–è´å¾Œã¯å†…å®¹ã‚’æŒ¯ã‚Šè¿”ã‚Šã€è¦ç‚¹ã‚’ã¾ã¨ã‚ã‚‹ã“ã¨ã§å­¦ç¿’åŠ¹æœãŒå‘ä¸Šã—ã¾ã™ã€‚"
                },
                {
                    "question": "åˆ†ã‹ã‚‰ãªã„éƒ¨åˆ†ãŒã‚ã£ãŸæ™‚ã®å¯¾å‡¦æ³•ã¨ã—ã¦æœ€é©ãªã®ã¯ï¼Ÿ",
                    "options": [
                        "ãã®ã¾ã¾é€²ã‚€",
                        "ä½•åº¦ã‚‚åŒã˜éƒ¨åˆ†ã‚’è¦‹ç›´ã™",
                        "è«¦ã‚ã¦ä»–ã®å‹•ç”»ã‚’è¦‹ã‚‹",
                        "é–¢é€£æƒ…å ±ã‚’èª¿ã¹ã¦ç†è§£ã‚’æ·±ã‚ã‚‹"
                    ],
                    "correct": 4,
                    "explanation": "åˆ†ã‹ã‚‰ãªã„éƒ¨åˆ†ã¯é–¢é€£æƒ…å ±ã‚’èª¿ã¹ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šæ·±ã„ç†è§£ã«ã¤ãªãŒã‚Šã¾ã™ã€‚"
                },
                {
                    "question": "ç¶™ç¶šçš„ãªå­¦ç¿’ã®ãŸã‚ã«æœ€ã‚‚å¤§åˆ‡ãªã“ã¨ã¯ï¼Ÿ",
                    "options": [
                        "æ¯æ—¥é•·æ™‚é–“å‹‰å¼·ã™ã‚‹",
                        "çŸ­æ™‚é–“ã§ã‚‚å®šæœŸçš„ã«ç¶šã‘ã‚‹",
                        "æ°—ãŒå‘ã„ãŸæ™‚ã ã‘ã‚„ã‚‹",
                        "å®Œç’§ã‚’ç›®æŒ‡ã—ã¦é ‘å¼µã‚‹"
                    ],
                    "correct": 2,
                    "explanation": "å­¦ç¿’ã¯çŸ­æ™‚é–“ã§ã‚‚å®šæœŸçš„ã«ç¶šã‘ã‚‹ã“ã¨ãŒã€é•·æœŸçš„ãªæˆæœã«ã¤ãªãŒã‚Šã¾ã™ã€‚"
                }
            ]
        }

    def try_ai_generation_sync(self, video_title, content_type, age_group):
        """åŒæœŸç‰ˆAIç”Ÿæˆè©¦è¡Œï¼ˆAIçµæœè¡¨ç¤ºå¯¾å¿œï¼‰"""
        print(f"â³ AIç”Ÿæˆè©¦è¡Œé–‹å§‹: {video_title}")
        
        try:
            # OpenAI APIè©¦è¡Œï¼ˆå°‘ã—æ¡ä»¶ã‚’ç·©å’Œï¼‰
            if self.openai_available:
                print("ğŸš€ OpenAI GPTã§ã‚¯ã‚¤ã‚ºç”Ÿæˆ")
                try:
                    # ã¾ãšè»½é‡ãªãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒªã§ç¢ºèª
                    test_result = self.test_openai_connection()
                    if test_result:
                        ai_result = self.generate_quiz_with_gpt_enhanced(
                            video_title, content_type, age_group
                        )
                        if ai_result and ai_result.get('questions'):
                            print(f"âœ… OpenAIç”ŸæˆæˆåŠŸ: {len(ai_result['questions'])}å•")
                            self.display_ai_generated_quiz(ai_result, "OpenAI GPT")
                            return ai_result
                except Exception as e:
                    print(f"âŒ OpenAIç”Ÿæˆå¤±æ•—: {e}")
            
            # Hugging Face APIè©¦è¡Œï¼ˆå®Ÿéš›ã®APIä½¿ç”¨ï¼‰
            if self.huggingface_api_key:
                print("ğŸ¤— Hugging Face API (å¼·åŒ–ç‰ˆ) ã§ã‚¯ã‚¤ã‚ºç”Ÿæˆã‚’è©¦è¡Œ")
                try:
                    # æ¥ç¶šãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
                    if self.test_huggingface_connection():
                        hf_result = self.generate_quiz_with_huggingface_real(
                            video_title, content_type, age_group
                        )
                        if hf_result and hf_result.get('questions'):
                            print(f"âœ… Hugging Faceç”ŸæˆæˆåŠŸ: {len(hf_result['questions'])}å•")
                            self.display_ai_generated_quiz(hf_result, f"Hugging Face ({hf_result.get('model', 'Unknown')})")
                            return hf_result
                    else:
                        print("âš ï¸ Hugging Faceæ¥ç¶šãƒ†ã‚¹ãƒˆå¤±æ•— - ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ç§»è¡Œ")
                except Exception as e:
                    print(f"âŒ Hugging Faceç”Ÿæˆå¤±æ•—: {e}")
            
            # ãƒ­ãƒ¼ã‚«ãƒ«AIã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
            print("ğŸ­ AIã‚¯ã‚¤ã‚ºç”Ÿæˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰")
            simulated_result = self.generate_ai_simulation_quiz(video_title, content_type, age_group)
            if simulated_result:
                self.display_ai_generated_quiz(simulated_result, "AI Simulation")
                return simulated_result
            
            print("âŒ ã™ã¹ã¦ã®AIç”ŸæˆãŒå¤±æ•—")
            return None
            
        except Exception as e:
            print(f"âŒ AIç”Ÿæˆè©¦è¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def test_openai_connection(self):
        """OpenAIæ¥ç¶šã®è»½é‡ãƒ†ã‚¹ãƒˆ"""
        try:
            # éå¸¸ã«è»½ã„ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "user", "content": "Hello"}
                ],
                max_tokens=5,
                temperature=0
            )
            print("âœ… OpenAIè»½é‡ãƒ†ã‚¹ãƒˆæˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ OpenAIè»½é‡ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
            return False

    def generate_quiz_with_gpt_enhanced(self, video_title, content_type, age_group):
        """æ‹¡å¼µç‰ˆGPTã‚¯ã‚¤ã‚ºç”Ÿæˆï¼ˆã‚ˆã‚Šç¢ºå®Ÿï¼‰"""
        if not self.openai_available:
            return None
        
        print(f"ğŸ¯ GPTå¼·åŒ–ç‰ˆç”Ÿæˆ: {age_group}å‘ã‘ - {content_type}")
        
        try:
            # ã‚ˆã‚Šå…·ä½“çš„ã§åŠ¹æœçš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            enhanced_prompt = self.build_enhanced_prompt(video_title, content_type, age_group)
            
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": f"ã‚ãªãŸã¯{age_group}å¹´é½¢å±¤å‘ã‘ã®æ•™è‚²ã‚¯ã‚¤ã‚ºä½œæˆã®å°‚é–€å®¶ã§ã™ã€‚å¿…ãšJSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
                    },
                    {
                        "role": "user",
                        "content": enhanced_prompt
                    }
                ],
                max_tokens=2000,
                temperature=0.7,
                response_format={"type": "json_object"}
            )
            
            quiz_json = response.choices[0].message.content
            quiz_data = json.loads(quiz_json)
            
            # ç”Ÿæˆæ–¹æ³•ã®æƒ…å ±ã‚’è¿½åŠ 
            quiz_data['generation_method'] = 'openai_gpt'
            quiz_data['model'] = 'gpt-3.5-turbo'
            quiz_data['content_type'] = content_type
            quiz_data['age_group'] = age_group
            
            if self.validate_quiz_structure(quiz_data):
                return quiz_data
            else:
                print("âŒ GPTç”ŸæˆçµæœãŒç„¡åŠ¹ãªæ§‹é€ ")
                return None
                
        except Exception as e:
            print(f"âŒ GPTå¼·åŒ–ç‰ˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def generate_quiz_with_huggingface_real(self, video_title, content_type, age_group):
        """å®Ÿéš›ã®Hugging Face APIä½¿ç”¨ï¼ˆä¿®æ­£ç‰ˆï¼‰"""
        print(f"ğŸ¤— Hugging Faceå®ŸAPIå‘¼ã³å‡ºã—: {video_title}")
        
        try:
            # ã‚ˆã‚Šé©åˆ‡ãªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ï¼ˆæ—¥æœ¬èªå¯¾å¿œï¼‰
            models_to_try = [
                "microsoft/DialoGPT-medium",
                "facebook/blenderbot-400M-distill",
                "google/flan-t5-small",
                "microsoft/DialoGPT-small"
            ]
            
            for model_name in models_to_try:
                try:
                    print(f"ğŸ”„ è©¦è¡Œä¸­ãƒ¢ãƒ‡ãƒ«: {model_name}")
                    result = self._try_huggingface_model(model_name, video_title, content_type, age_group)
                    if result:
                        return result
                except Exception as model_error:
                    print(f"âŒ {model_name} å¤±æ•—: {model_error}")
                    continue
            
            print("âŒ å…¨ã¦ã®Hugging Faceãƒ¢ãƒ‡ãƒ«ã§å¤±æ•—")
            return None
                
        except Exception as e:
            print(f"âŒ Hugging Faceå®ŸAPI ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def _try_huggingface_model(self, model_name, video_title, content_type, age_group):
        """å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«ã§ã®è©¦è¡Œ"""
        api_url = f"https://api-inference.huggingface.co/models/{model_name}"
        
        headers = {
            "Authorization": f"Bearer {self.huggingface_api_key}",
            "Content-Type": "application/json"
        }
        
        # æ—¥æœ¬èªå¯¾å¿œã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆçŸ­ç¸®ç‰ˆï¼‰
        prompt = self.build_simple_japanese_prompt(video_title, content_type, age_group)
        
        # ãƒ¢ãƒ‡ãƒ«ã«å¿œã˜ãŸãƒšã‚¤ãƒ­ãƒ¼ãƒ‰èª¿æ•´
        if "flan-t5" in model_name:
            payload = {
                "inputs": prompt,
                "parameters": {
                    "max_new_tokens": 500,
                    "temperature": 0.7,
                    "do_sample": True
                },
                "options": {
                    "wait_for_model": True,
                    "use_cache": False
                }
            }
        elif "blenderbot" in model_name:
            payload = {
                "inputs": prompt,
                "parameters": {
                    "max_length": 200,
                    "min_length": 50,
                    "temperature": 0.8
                },
                "options": {
                    "wait_for_model": True
                }
            }
        else:  # DialoGPTç³»
            payload = {
                "inputs": prompt,
                "parameters": {
                    "max_new_tokens": 300,
                    "temperature": 0.7,
                    "pad_token_id": 50256
                },
                "options": {
                    "wait_for_model": True
                }
            }
        
        import requests
        response = requests.post(
            api_url, 
            headers=headers, 
            json=payload, 
            timeout=30
        )
        
        print(f"ğŸ“¡ {model_name} å¿œç­”ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status_code}")
        
        if response.status_code == 200:
            result = response.json()
            print(f"âœ… {model_name} æˆåŠŸå¿œç­”")
            
            # çµæœã‚’è§£æã—ã¦ã‚¯ã‚¤ã‚ºå½¢å¼ã«å¤‰æ›
            quiz_data = self.parse_huggingface_response_enhanced(
                result, video_title, content_type, age_group, model_name
            )
            return quiz_data
            
        elif response.status_code == 503:
            print(f"â³ {model_name} ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
            # å°‘ã—å¾…ã£ã¦ãƒªãƒˆãƒ©ã‚¤
            import time
            time.sleep(3)
            return self._retry_huggingface_request(api_url, headers, payload, model_name)
            
        else:
            error_text = response.text
            print(f"âŒ {model_name} ã‚¨ãƒ©ãƒ¼ {response.status_code}: {error_text}")
            return None

    def _retry_huggingface_request(self, api_url, headers, payload, model_name):
        """Hugging Face APIã®ãƒªãƒˆãƒ©ã‚¤"""
        try:
            import requests
            import time
            
            print(f"ğŸ”„ {model_name} ãƒªãƒˆãƒ©ã‚¤å®Ÿè¡Œ")
            time.sleep(2)
            
            response = requests.post(api_url, headers=headers, json=payload, timeout=25)
            
            if response.status_code == 200:
                result = response.json()
                print(f"âœ… {model_name} ãƒªãƒˆãƒ©ã‚¤æˆåŠŸ")
                return result
            else:
                print(f"âŒ {model_name} ãƒªãƒˆãƒ©ã‚¤å¤±æ•—: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"âŒ {model_name} ãƒªãƒˆãƒ©ã‚¤ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def build_simple_japanese_prompt(self, video_title, content_type, age_group):
        """ã‚·ãƒ³ãƒ—ãƒ«ãªæ—¥æœ¬èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰"""
        age_descriptions = {
            'elementary_low': 'å°å­¦1-3å¹´',
            'elementary_mid': 'å°å­¦4-6å¹´', 
            'junior_high': 'ä¸­å­¦ç”Ÿ',
            'general': 'ä¸€èˆ¬'
        }
        
        age_desc = age_descriptions.get(age_group, 'ä¸€èˆ¬')
        
        # ã‚ˆã‚ŠçŸ­ãã‚·ãƒ³ãƒ—ãƒ«ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        return f"""å‹•ç”»ã€Œ{video_title}ã€ã«ã¤ã„ã¦ã€{age_desc}å‘ã‘ã®{content_type}ã®4æŠã‚¯ã‚¤ã‚ºã‚’1å•ä½œæˆã—ã¦ãã ã•ã„ã€‚

å½¢å¼:
å•é¡Œ: [å•é¡Œæ–‡]
A) [é¸æŠè‚¢1]
B) [é¸æŠè‚¢2]  
C) [é¸æŠè‚¢3]
D) [é¸æŠè‚¢4]
æ­£è§£: [A/B/C/D]
è§£èª¬: [è§£èª¬æ–‡]"""

    def parse_huggingface_response_enhanced(self, response, video_title, content_type, age_group, model_name):
        """Hugging Faceå¿œç­”ã®å¼·åŒ–ç‰ˆè§£æ"""
        try:
            # å¿œç­”ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
            generated_text = ""
            
            if isinstance(response, list) and len(response) > 0:
                if isinstance(response[0], dict):
                    generated_text = response[0].get('generated_text', '') or \
                                   response[0].get('text', '') or \
                                   response[0].get('translation_text', '') or \
                                   str(response[0])
                else:
                    generated_text = str(response[0])
            elif isinstance(response, dict):
                generated_text = response.get('generated_text', '') or \
                               response.get('text', '') or \
                               response.get('translation_text', '') or \
                               str(response)
            else:
                generated_text = str(response)
            
            print(f"ğŸ” {model_name} ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆ:\n{generated_text[:200]}...")
            
            # ãƒ†ã‚­ã‚¹ãƒˆã‚’è§£æã—ã¦ã‚¯ã‚¤ã‚ºæ§‹é€ ã«å¤‰æ›
            questions = self.extract_questions_from_text_enhanced(generated_text, video_title, content_type)
            
            # æœ€ä½é™ã®å•é¡Œæ•°ã‚’ç¢ºä¿
            if len(questions) < 3:
                print(f"âš ï¸ {model_name} ç”Ÿæˆå•é¡Œæ•°ä¸è¶³ - è£œå®Œå®Ÿè¡Œ")
                questions.extend(self.generate_fallback_hf_questions(video_title, content_type, 3 - len(questions)))
            
            return {
                "generation_method": "huggingface_real",
                "model": model_name,
                "content_type": content_type,
                "age_group": age_group,
                "video_title": video_title,
                "questions": questions[:5],  # æœ€å¤§5å•
                "raw_response": generated_text,
                "hf_success": True
            }
            
        except Exception as e:
            print(f"âŒ {model_name} å¿œç­”è§£æã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚åŸºæœ¬çš„ãªã‚¯ã‚¤ã‚ºã‚’è¿”ã™
            return self.generate_hf_fallback_quiz(video_title, content_type, age_group, model_name)

    def extract_questions_from_text_enhanced(self, text, video_title, content_type):
        """å¼·åŒ–ç‰ˆãƒ†ã‚­ã‚¹ãƒˆè§£æï¼ˆã‚ˆã‚Šå¤šæ§˜ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾å¿œï¼‰"""
        questions = []
        
        try:
            import re
            
            # è¤‡æ•°ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã§å•é¡Œã‚’æ¤œç´¢
            patterns = [
                r'å•é¡Œ[:ï¼š]\s*(.+?)(?=å•é¡Œ|$)',
                r'Q\d+[:ï¼š]\s*(.+?)(?=Q\d+|$)',
                r'è³ªå•[:ï¼š]\s*(.+?)(?=è³ªå•|$)',
                r'[1-9][:ï¼š]\s*(.+?)(?=[1-9][:ï¼š]|$)'
            ]
            
            extracted_problems = []
            for pattern in patterns:
                matches = re.findall(pattern, text, re.DOTALL | re.IGNORECASE)
                extracted_problems.extend(matches)
                if extracted_problems:
                    break
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãŒå¤±æ•—ã—ãŸå ´åˆã¯æ–‡ç« ã‚’åˆ†å‰²
            if not extracted_problems:
                sentences = text.split('ã€‚')
                extracted_problems = [s.strip() for s in sentences if len(s.strip()) > 20]
            
            for i, problem_text in enumerate(extracted_problems[:3]):
                # é¸æŠè‚¢ã‚’æŠ½å‡ºã¾ãŸã¯ç”Ÿæˆ
                options = self.extract_or_generate_options(problem_text, content_type)
                
                question_data = {
                    "question": f"Hugging Faceç”Ÿæˆ: {video_title}ã«é–¢é€£ã™ã‚‹å•é¡Œ {i+1}",
                    "options": options,
                    "correct": 2,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§2ç•ªç›®ã‚’æ­£è§£
                    "explanation": f"Hugging Faceã«ã‚ˆã‚‹è§£æ: {problem_text[:100]}..."
                }
                questions.append(question_data)
            
            return questions
            
        except Exception as e:
            print(f"âŒ å¼·åŒ–ç‰ˆãƒ†ã‚­ã‚¹ãƒˆè§£æã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def extract_or_generate_options(self, problem_text, content_type):
        """é¸æŠè‚¢ã‚’æŠ½å‡ºã¾ãŸã¯ç”Ÿæˆ"""
        try:
            import re
            
            # A) B) C) D)ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
            option_pattern = r'[A-D]\)\s*([^\n\r]+)'
            options = re.findall(option_pattern, problem_text)
            
            if len(options) >= 4:
                return options[:4]
            
            # æ•°å­—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
            number_pattern = r'[1-4][:ï¼š]\s*([^\n\r]+)'
            number_options = re.findall(number_pattern, problem_text)
            
            if len(number_options) >= 4:
                return number_options[:4]
            
            # è‡ªå‹•ç”Ÿæˆ
            return self.generate_context_options(content_type)
            
        except Exception as e:
            print(f"âŒ é¸æŠè‚¢æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return self.generate_context_options(content_type)

    def generate_context_options(self, content_type):
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸé¸æŠè‚¢ç”Ÿæˆ"""
        options_map = {
            'math': [
                'è¨ˆç®—ã‚’æ­£ç¢ºã«è¡Œã†',
                'æ¦‚å¿µã‚’ç†è§£ã™ã‚‹', 
                'æš—è¨˜ã«é ¼ã‚‹',
                'ç­”ãˆã ã‘æ±‚ã‚ã‚‹'
            ],
            'geography': [
                'åœ°åã‚’æš—è¨˜ã™ã‚‹',
                'åœ°å›³ã§ä½ç½®ã‚’ç¢ºèªã™ã‚‹',
                'èˆˆå‘³ã‚’æŒãŸãªã„',
                'ãƒ†ã‚¹ãƒˆã®ãŸã‚ã ã‘'
            ],
            'history': [
                'å¹´å·ã‚’è¦šãˆã‚‹',
                'èƒŒæ™¯ã‚’ç†è§£ã™ã‚‹',
                'èˆˆå‘³ã‚’æŒãŸãªã„', 
                'è¡¨é¢çš„ã«å­¦ã¶'
            ],
            'science': [
                'å®Ÿé¨“ã‚’ã™ã‚‹',
                'ç†è«–ã‚’å­¦ã¶',
                'æš—è¨˜ã ã‘ã™ã‚‹',
                'é–¢å¿ƒã‚’æŒãŸãªã„'
            ]
        }
        
        return options_map.get(content_type, [
            'ç©æ¥µçš„ã«å­¦ç¿’',
            'ç†è§£ã‚’æ·±ã‚ã‚‹',
            'å—å‹•çš„å­¦ç¿’',
            'è¡¨é¢çš„å­¦ç¿’'
        ])

    def generate_fallback_hf_questions(self, video_title, content_type, count):
        """Hugging Faceç”¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å•é¡Œ"""
        questions = []
        
        for i in range(count):
            question_data = {
                "question": f"Hugging Faceè£œå®Œå•é¡Œ {i+1}: {video_title}ã®ã‚ˆã†ãª{content_type}å­¦ç¿’ã§é‡è¦ãªã®ã¯ï¼Ÿ",
                "options": self.generate_context_options(content_type),
                "correct": 2,
                "explanation": f"Hugging Faceã®è§£æã‚’è£œå®Œã—ãŸ{content_type}åˆ†é‡ã®å­¦ç¿’ãƒã‚¤ãƒ³ãƒˆã§ã™ã€‚"
            }
            questions.append(question_data)
        
        return questions

    def generate_hf_fallback_quiz(self, video_title, content_type, age_group, model_name):
        """Hugging Faceå®Œå…¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        print(f"ğŸ”„ {model_name} å®Œå…¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ")
        
        return {
            "generation_method": "huggingface_fallback",
            "model": model_name,
            "content_type": content_type,
            "age_group": age_group,
            "video_title": video_title,
            "questions": [
                {
                    "question": f"Hugging Face ({model_name}) è§£æ: {video_title}ã®å­¦ç¿’ã§æœ€ã‚‚åŠ¹æœçš„ãªã®ã¯ï¼Ÿ",
                    "options": [
                        "è¡¨é¢çš„ãªç†è§£",
                        "æ·±ã„ç†è§£ã¨å¿œç”¨",
                        "æš—è¨˜ä¸­å¿ƒ",
                        "å—å‹•çš„å­¦ç¿’"
                    ],
                    "correct": 2,
                    "explanation": f"{model_name}ã«ã‚ˆã‚‹{content_type}åˆ†é‡ã®å­¦ç¿’åˆ†æçµæœã§ã™ã€‚"
                },
                {
                    "question": f"Hugging Faceæ¨å¥¨: {content_type}åˆ†é‡ã®åŠ¹æœçš„ãªå­¦ç¿’æ–¹æ³•ã¯ï¼Ÿ",
                    "options": self.generate_context_options(content_type),
                    "correct": 2,
                    "explanation": f"{model_name}ãŒæ¨å¥¨ã™ã‚‹{content_type}å­¦ç¿’ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã§ã™ã€‚"
                },
                {
                    "question": f"{age_group}å‘ã‘å­¦ç¿’ã§{model_name}ãŒé‡è¦–ã™ã‚‹ã®ã¯ï¼Ÿ",
                    "options": [
                        "é€Ÿåº¦é‡è¦–",
                        "ç†è§£é‡è¦–",
                        "é‡é‡è¦–", 
                        "è©•ä¾¡é‡è¦–"
                    ],
                    "correct": 2,
                    "explanation": f"{model_name}ã«ã‚ˆã‚‹{age_group}å‘ã‘å­¦ç¿’ã®æœ€é©åŒ–ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã§ã™ã€‚"
                }
            ],
            "hf_fallback": True,
            "fallback_reason": f"{model_name} APIå¿œç­”è§£æå¤±æ•—"
        }

    def test_huggingface_connection(self):
        """Hugging Faceæ¥ç¶šãƒ†ã‚¹ãƒˆ"""
        if not self.huggingface_api_key:
            print("âŒ Hugging Face APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
        
        try:
            import requests
            
            # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ†ã‚¹ãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            test_models = [
                "microsoft/DialoGPT-small",
                "google/flan-t5-small"
            ]
            
            for model in test_models:
                print(f"ğŸ” {model} æ¥ç¶šãƒ†ã‚¹ãƒˆä¸­...")
                
                url = f"https://api-inference.huggingface.co/models/{model}"
                headers = {"Authorization": f"Bearer {self.huggingface_api_key}"}
                
                response = requests.post(
                    url,
                    headers=headers,
                    json={"inputs": "Hello, test"},
                    timeout=10
                )
                
                print(f"ğŸ“¡ {model} å¿œç­”: {response.status_code}")
                
                if response.status_code in [200, 503]:  # 503ã¯ã€Œãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­ã€
                    print(f"âœ… {model} æ¥ç¶šæˆåŠŸ")
                    return True
                else:
                    print(f"âŒ {model} æ¥ç¶šå¤±æ•—: {response.text[:100]}")
            
            return False
            
        except Exception as e:
            print(f"âŒ Hugging Faceæ¥ç¶šãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def try_ai_generation_sync(self, video_title, content_type, age_group):
        """åŒæœŸç‰ˆAIç”Ÿæˆè©¦è¡Œï¼ˆHugging Faceå¼·åŒ–ç‰ˆï¼‰"""
        print(f"â³ AIç”Ÿæˆè©¦è¡Œé–‹å§‹: {video_title}")
        
        try:
            # OpenAI APIè©¦è¡Œ
            if self.openai_available:
                print("ğŸš€ OpenAI GPTã§ã‚¯ã‚¤ã‚ºç”Ÿæˆ")
                try:
                    test_result = self.test_openai_connection()
                    if test_result:
                        ai_result = self.generate_quiz_with_gpt_enhanced(
                            video_title, content_type, age_group
                        )
                        if ai_result and ai_result.get('questions'):
                            print(f"âœ… OpenAIç”ŸæˆæˆåŠŸ: {len(ai_result['questions'])}å•")
                            self.display_ai_generated_quiz(ai_result, "OpenAI GPT")
                            return ai_result
                except Exception as e:
                    print(f"âŒ OpenAIç”Ÿæˆå¤±æ•—: {e}")
            
            # Hugging Face APIè©¦è¡Œï¼ˆå¼·åŒ–ç‰ˆï¼‰
            if self.huggingface_api_key:
                print("ğŸ¤— Hugging Face API (å¼·åŒ–ç‰ˆ) ã§ã‚¯ã‚¤ã‚ºç”Ÿæˆã‚’è©¦è¡Œ")
                try:
                    # æ¥ç¶šãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
                    if self.test_huggingface_connection():
                        hf_result = self.generate_quiz_with_huggingface_real(
                            video_title, content_type, age_group
                        )
                        if hf_result and hf_result.get('questions'):
                            print(f"âœ… Hugging Faceç”ŸæˆæˆåŠŸ: {len(hf_result['questions'])}å•")
                            self.display_ai_generated_quiz(hf_result, f"Hugging Face ({hf_result.get('model', 'Unknown')})")
                            return hf_result
                    else:
                        print("âš ï¸ Hugging Faceæ¥ç¶šãƒ†ã‚¹ãƒˆå¤±æ•— - ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ç§»è¡Œ")
                except Exception as e:
                    print(f"âŒ Hugging Faceç”Ÿæˆå¤±æ•—: {e}")
            
            # ãƒ­ãƒ¼ã‚«ãƒ«AIã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            print("ğŸ­ AIã‚¯ã‚¤ã‚ºç”Ÿæˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰")
            simulated_result = self.generate_ai_simulation_quiz(video_title, content_type, age_group)
            if simulated_result:
                self.display_ai_generated_quiz(simulated_result, "AI Simulation")
                return simulated_result
            
            print("âŒ ã™ã¹ã¦ã®AIç”ŸæˆãŒå¤±æ•—")
            return None
            
        except Exception as e:
            print(f"âŒ AIç”Ÿæˆè©¦è¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def set_debug_mode(self, force_fallback=False, force_ai_failure=False, test_mode=False):
        """ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã®è¨­å®š"""
        self.debug_settings.update({
            'force_fallback': force_fallback,
            'force_ai_failure': force_ai_failure,
            'test_mode': test_mode
        })
        print(f"ğŸ”§ ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰è¨­å®š: {self.debug_settings}")

    def display_ai_generated_quiz(self, quiz_data, ai_source):
        """AIç”Ÿæˆã•ã‚ŒãŸã‚¯ã‚¤ã‚ºã®è¡¨ç¤º"""
        print(f"\nğŸ¤– {ai_source} ã§ç”Ÿæˆã•ã‚ŒãŸã‚¯ã‚¤ã‚º:")
        print(f"  - ç”Ÿæˆæ–¹æ³•: {quiz_data.get('generation_method', 'unknown')}")
        print(f"  - å•é¡Œæ•°: {len(quiz_data.get('questions', []))}")
        print(f"  - ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—: {quiz_data.get('content_type', 'unknown')}")
        print(f"  - å¯¾è±¡å¹´é½¢: {quiz_data.get('age_group', 'unknown')}")
        
        for i, question in enumerate(quiz_data.get('questions', [])[:3], 1):
            print(f"\n  å•é¡Œ{i}: {question.get('question', '')[:50]}...")
            print(f"  æ­£è§£: {question.get('correct', 0)}ç•ª - {question.get('options', [''])[question.get('correct', 1)-1]}")

    def build_enhanced_prompt(self, video_title, content_type, age_group):
        """å¼·åŒ–ç‰ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰"""
        age_descriptions = {
            'elementary_low': 'å°å­¦1-3å¹´',
            'elementary_mid': 'å°å­¦4-6å¹´', 
            'junior_high': 'ä¸­å­¦ç”Ÿ',
            'general': 'ä¸€èˆ¬'
        }
        
        age_desc = age_descriptions.get(age_group, 'ä¸€èˆ¬')
        
        prompt = f"""
å‹•ç”»ã€Œ{video_title}ã€ã«ã¤ã„ã¦ã€{age_desc}å‘ã‘ã®{content_type}åˆ†é‡ã®ã‚¯ã‚¤ã‚ºã‚’5å•ä½œæˆã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
{{
    "questions": [
        {{
            "question": "å•é¡Œæ–‡",
            "options": ["é¸æŠè‚¢1", "é¸æŠè‚¢2", "é¸æŠè‚¢3", "é¸æŠè‚¢4"],
            "correct": 2,
            "explanation": "è§£èª¬æ–‡",
            "difficulty_level": "medium"
        }}
    ]
}}

è¦ä»¶:
- 4æŠå•é¡Œ
- æ­£è§£ã¯1-4ã®æ•°å­—
- ã‚ã‹ã‚Šã‚„ã™ã„è§£èª¬
- {age_desc}ã«é©ã—ãŸé›£æ˜“åº¦
"""
        return prompt

    def validate_quiz_structure(self, quiz_data):
        """ã‚¯ã‚¤ã‚ºæ§‹é€ ã®æ¤œè¨¼"""
        if not isinstance(quiz_data, dict):
            return False
        
        questions = quiz_data.get('questions', [])
        if not isinstance(questions, list) or len(questions) == 0:
            return False
        
        for question in questions:
            if not all(key in question for key in ['question', 'options', 'correct', 'explanation']):
                return False
            
            if not isinstance(question['options'], list) or len(question['options']) != 4:
                return False
            
            if not isinstance(question['correct'], int) or question['correct'] not in [1, 2, 3, 4]:
                return False
        
        return True

    def generate_age_specific_quiz(self, video_title, content_type, age_group, transcript):
        """å¹´é½¢ç‰¹åŒ–å‹ã‚¯ã‚¤ã‚ºç”Ÿæˆ"""
        print(f"ğŸ¯ å¹´é½¢ç‰¹åŒ–å‹ã‚¯ã‚¤ã‚ºç”Ÿæˆ: {age_group} - {content_type}")
        
        if age_group == 'elementary_low':
            return self.generate_elementary_low_quiz(video_title, content_type, transcript)
        elif content_type == 'math':
            return self.generate_math_fallback_quiz(video_title)
        else:
            return self.generate_general_fallback_quiz(video_title, content_type, age_group)

    def generate_general_fallback_quiz(self, video_title, content_type, age_group):
        """ä¸€èˆ¬çš„ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¯ã‚¤ã‚º"""
        print(f"ğŸ“š ä¸€èˆ¬ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”Ÿæˆ: {content_type} - {age_group}")
        
        return {
            "quiz_type": "general_fallback",
            "content_type": content_type,
            "age_group": age_group,
            "generation_method": "fallback",
            "questions": [
                {
                    "question": f"ã€Œ{video_title}ã€ã®ã‚ˆã†ãª{content_type}ã®å­¦ç¿’ã§é‡è¦ãªã“ã¨ã¯ï¼Ÿ",
                    "options": [
                        "æš—è¨˜ã ã‘ã«é›†ä¸­ã™ã‚‹",
                        "ç†è§£ã‚’æ·±ã‚ã‚‹ã“ã¨ã‚’é‡è¦–ã™ã‚‹",
                        "é€Ÿåº¦ã ã‘ã‚’è¿½æ±‚ã™ã‚‹",
                        "ä»–äººã¨æ¯”è¼ƒã™ã‚‹ã“ã¨ã‚’é‡è¦–ã™ã‚‹"
                    ],
                    "correct": 2,
                    "explanation": f"{content_type}åˆ†é‡ã§ã¯ç†è§£ã‚’æ·±ã‚ã‚‹ã“ã¨ãŒæœ€ã‚‚é‡è¦ã§ã™ã€‚"
                },
                {
                    "question": f"{age_group}å‘ã‘ã®å­¦ç¿’æ–¹æ³•ã¨ã—ã¦æœ€é©ãªã®ã¯ï¼Ÿ",
                    "options": [
                        "ä¸€åº¦ã§å®Œç’§ã«è¦šãˆã‚‹",
                        "æ®µéšçš„ã«å­¦ç¿’ã‚’é€²ã‚ã‚‹",
                        "é›£ã—ã„å†…å®¹ã‹ã‚‰å§‹ã‚ã‚‹",
                        "æ™‚é–“ã‚’ã‹ã‘ãšã«çµ‚ã‚ã‚‰ã›ã‚‹"
                    ],
                    "correct": 2,
                    "explanation": "æ®µéšçš„ãªå­¦ç¿’ãŒç†è§£ã‚’æ·±ã‚ã€è¨˜æ†¶å®šç€ã«åŠ¹æœçš„ã§ã™ã€‚"
                },
                {
                    "question": "åŠ¹æœçš„ãªå¾©ç¿’ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã¯ï¼Ÿ",
                    "options": [
                        "å­¦ç¿’ç›´å¾Œã®ã¿",
                        "å¿˜ã‚Œã‹ã‘ãŸé ƒã«è¡Œã†",
                        "è©¦é¨“å‰ã ã‘",
                        "æ°—ãŒå‘ã„ãŸæ™‚ã«è¡Œã†"
                    ],
                    "correct": 2,
                    "explanation": "å¿˜å´æ›²ç·šã«åŸºã¥ãã€å¿˜ã‚Œã‹ã‘ãŸé ƒã®å¾©ç¿’ãŒæœ€ã‚‚åŠ¹æœçš„ã§ã™ã€‚"
                },
                {
                    "question": "å­¦ç¿’å†…å®¹ã‚’å®šç€ã•ã›ã‚‹ãŸã‚ã«æœ‰åŠ¹ãªã®ã¯ï¼Ÿ",
                    "options": [
                        "è¦‹ã‚‹ã ã‘ã®å­¦ç¿’",
                        "æ‰‹ã‚’å‹•ã‹ã—ã¦ç·´ç¿’ã™ã‚‹",
                        "èãã ã‘ã®å­¦ç¿’",
                        "è€ƒãˆãšã«æš—è¨˜ã™ã‚‹"
                    ],
                    "correct": 2,
                    "explanation": "ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ã—ã¦æ‰‹ã‚’å‹•ã‹ã™ã“ã¨ãŒè¨˜æ†¶å®šç€ã«æœ‰åŠ¹ã§ã™ã€‚"
                },
                {
                    "question": "ç¶™ç¶šçš„ãªå­¦ç¿’ã®ã‚³ãƒ„ã¯ï¼Ÿ",
                    "options": [
                        "æ¯æ—¥é•·æ™‚é–“ã‚„ã‚‹",
                        "çŸ­æ™‚é–“ã§ã‚‚ç¶™ç¶šã™ã‚‹",
                        "å®Œç’§ã‚’ç›®æŒ‡ã™",
                        "ä¸€äººã§é ‘å¼µã‚‹"
                    ],
                    "correct": 2,
                    "explanation": "çŸ­æ™‚é–“ã§ã‚‚ç¶™ç¶šã™ã‚‹ã“ã¨ãŒé•·æœŸçš„ãªå­¦ç¿’åŠ¹æœã«ã¤ãªãŒã‚Šã¾ã™ã€‚"
                }
            ]
        }

    def generate_history_quiz(self, video, Quiz):
        """æ­´å²å°‚ç”¨ã‚¯ã‚¤ã‚ºç”Ÿæˆ"""
        history_questions = [
            {
                'question': 'æ—¥æœ¬ã®å…ƒå·ã§æœ€ã‚‚é•·ãç¶šã„ãŸã®ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ',
                'options': ['æ˜æ²»', 'æ˜­å’Œ', 'å¹³æˆ', 'å¤§æ­£'],
                'correct': 2,
                'explanation': 'æ˜­å’Œã¯1926å¹´ã‹ã‚‰1989å¹´ã¾ã§64å¹´é–“ç¶šãã€æ—¥æœ¬å²ä¸Šæœ€ã‚‚é•·ã„å…ƒå·ã§ã™ã€‚'
            },
            {
                'question': 'æ±Ÿæˆ¸å¹•åºœã‚’é–‹ã„ãŸå¾³å·å®¶åº·ãŒå¾å¤·å¤§å°†è»ã«ä»»å‘½ã•ã‚ŒãŸå¹´ã¯ï¼Ÿ',
                'options': ['1600å¹´', '1603å¹´', '1615å¹´', '1598å¹´'],
                'correct': 2,
                'explanation': 'å¾³å·å®¶åº·ã¯1603å¹´ã«å¾å¤·å¤§å°†è»ã«ä»»å‘½ã•ã‚Œã€æ±Ÿæˆ¸å¹•åºœã‚’é–‹ãã¾ã—ãŸã€‚'
            },
            {
                'question': 'æ˜æ²»ç¶­æ–°ã§æ´»èºã—ãŸã€Œç¶­æ–°ã®ä¸‰å‚‘ã€ã«å«ã¾ã‚Œãªã„ã®ã¯ï¼Ÿ',
                'options': ['è¥¿éƒ·éš†ç››', 'å¤§ä¹…ä¿åˆ©é€š', 'æœ¨æˆ¸å­å…', 'å‚æœ¬é¾é¦¬'],
                'correct': 4,
                'explanation': 'ç¶­æ–°ã®ä¸‰å‚‘ã¯è¥¿éƒ·éš†ç››ã€å¤§ä¹…ä¿åˆ©é€šã€æœ¨æˆ¸å­å…ã§ã™ã€‚å‚æœ¬é¾é¦¬ã¯ç¶­æ–°ã®ç«‹å½¹è€…ã§ã™ãŒä¸‰å‚‘ã«ã¯å«ã¾ã‚Œã¾ã›ã‚“ã€‚'
            },
            {
                'question': 'å¹³å®‰æ™‚ä»£ã®éƒ½ã¯ã©ã“ã«ç½®ã‹ã‚Œã¾ã—ãŸã‹ï¼Ÿ',
                'options': ['å¥ˆè‰¯', 'äº¬éƒ½', 'å¤§é˜ª', 'æ±äº¬'],
                'correct': 2,
                'explanation': 'å¹³å®‰æ™‚ä»£ï¼ˆ794-1185å¹´ï¼‰ã®éƒ½ã¯å¹³å®‰äº¬ã€ç¾åœ¨ã®äº¬éƒ½ã«ç½®ã‹ã‚Œã¾ã—ãŸã€‚'
            },
            {
                'question': 'æˆ¦å›½æ™‚ä»£ã®ä¸‰è‹±å‚‘ã¨å‘¼ã°ã‚Œã‚‹ã®ã¯ï¼Ÿ',
                'options': [
                    'ç¹”ç”°ä¿¡é•·ãƒ»è±Šè‡£ç§€å‰ãƒ»å¾³å·å®¶åº·',
                    'æ­¦ç”°ä¿¡ç„ãƒ»ä¸Šæ‰è¬™ä¿¡ãƒ»ç¹”ç”°ä¿¡é•·',
                    'è¶³åˆ©å°Šæ°ãƒ»æ–°ç”°ç¾©è²ãƒ»æ¥ æœ¨æ­£æˆ',
                    'æºé ¼æœãƒ»æºç¾©çµŒãƒ»å¹³æ¸…ç››'
                ],
                'correct': 1,
                'explanation': 'æˆ¦å›½ä¸‰è‹±å‚‘ã¯ç¹”ç”°ä¿¡é•·ã€è±Šè‡£ç§€å‰ã€å¾³å·å®¶åº·ã§ã™ã€‚ã“ã®3äººãŒæˆ¦å›½æ™‚ä»£ã®çµ±ä¸€ã‚’æˆã—é‚ã’ã¾ã—ãŸã€‚'
            }
        ]
        
        created_count = 0
        for i, q_data in enumerate(history_questions, 1):
            try:
                quiz = Quiz.objects.create(
                    video=video,
                    question=q_data['question'],
                    option_1=q_data['options'][0],
                    option_2=q_data['options'][1],
                    option_3=q_data['options'][2],
                    option_4=q_data['options'][3],
                    correct_option=q_data['correct'],
                    explanation=q_data['explanation'],
                    difficulty_level='medium'
                )
                
                if hasattr(quiz, 'order'):
                    quiz.order = i
                    quiz.save()
                
                created_count += 1
                print(f"âœ… æ­´å²å•é¡Œ{i}: {quiz.question[:50]}...")
                
            except Exception as e:
                print(f"âŒ æ­´å²å•é¡Œ{i}ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        return created_count

    def generate_quiz_with_whisper_pipeline(self, video_id, user=None):
        """WhisperéŸ³å£°å‡¦ç†â†’è¦ç´„â†’ã‚¯ã‚¤ã‚ºç”Ÿæˆã®å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""
        try:
            print(f"ğŸµ Whisperãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹: å‹•ç”»ID {video_id}")
            
            from django.apps import apps
            LearningVideo = apps.get_model('playlist', 'LearningVideo')
            video = LearningVideo.objects.get(id=video_id)
            
            print(f"ğŸ¬ å‡¦ç†å¯¾è±¡å‹•ç”»: {video.title}")
            
            # Step 1: éŸ³å£°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            audio_file_path = self.download_audio_from_youtube(video.video_id)
            if not audio_file_path:
                print("âŒ éŸ³å£°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•— - ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«ç§»è¡Œ")
                return self.execute_fallback_generation(video_id, user)
            
            # Step 2: Whisperã§éŸ³å£°ã‚’å­—å¹•åŒ–
            transcript = self.transcribe_audio_with_whisper(audio_file_path)
            if not transcript:
                print("âŒ éŸ³å£°å­—å¹•åŒ–å¤±æ•— - ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«ç§»è¡Œ")
                self.cleanup_temp_file(audio_file_path)
                return self.execute_fallback_generation(video_id, user)
            
            # Step 3: ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’è¦ç´„
            summary = self.summarize_transcript(transcript)
            if not summary:
                print("âŒ è¦ç´„å‡¦ç†å¤±æ•— - ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«ç§»è¡Œ")
                self.cleanup_temp_file(audio_file_path)
                return self.execute_fallback_generation(video_id, user)
            
            # Step 4: è¦ç´„ã‹ã‚‰ã‚¯ã‚¤ã‚ºç”Ÿæˆ
            quiz_data = self.generate_quiz_from_summary(video.title, summary, user)
            
            # Step 5: ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            self.cleanup_temp_file(audio_file_path)
            
            if quiz_data and quiz_data.get('questions'):
                quiz_data['generation_method'] = 'whisper_pipeline'
                quiz_data['transcript_length'] = len(transcript)
                quiz_data['summary_length'] = len(summary)
                quiz_data['audio_processed'] = True
                
                print(f"âœ… Whisperãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†: {len(quiz_data['questions'])}å•ç”Ÿæˆ")
                return quiz_data
            else:
                print("âŒ ã‚¯ã‚¤ã‚ºç”Ÿæˆå¤±æ•— - ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«ç§»è¡Œ")
                return self.execute_fallback_generation(video_id, user)
                
        except Exception as e:
            print(f"âŒ Whisperãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
            return self.execute_fallback_generation(video_id, user, error_message=str(e))

    def download_audio_from_youtube(self, youtube_video_id):
        """YouTubeã‹ã‚‰éŸ³å£°ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        try:
            print(f"â¬‡ï¸ YouTubeéŸ³å£°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {youtube_video_id}")
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
            temp_dir = tempfile.gettempdir()
            audio_file = os.path.join(temp_dir, f"youtube_audio_{youtube_video_id}.wav")
            
            # yt-dlpã®è¨­å®š
            ydl_opts = {
                'format': 'bestaudio/best',
                'outtmpl': audio_file.replace('.wav', '.%(ext)s'),
                'postprocessors': [{
                    'key': 'FFmpegExtractAudio',
                    'preferredcodec': 'wav',
                    'preferredquality': '192',
                }],
                'quiet': True,
                'no_warnings': True,
                'extractaudio': True,
                'audioformat': 'wav',
                'audioquality': 192,
            }
            
            url = f"https://www.youtube.com/watch?v={youtube_video_id}"
            
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                # å‹•ç”»æƒ…å ±ã‚’å–å¾—
                info = ydl.extract_info(url, download=False)
                duration = info.get('duration', 0)
                
                # é•·æ™‚é–“å‹•ç”»ã®åˆ¶é™ï¼ˆ10åˆ†ä»¥ä¸Šã¯æœ€åˆã®10åˆ†ã®ã¿ï¼‰
                if duration > 600:  # 10åˆ†
                    print(f"âš ï¸ é•·æ™‚é–“å‹•ç”»({duration}ç§’) - æœ€åˆã®10åˆ†ã®ã¿å‡¦ç†")
                    ydl_opts['postprocessor_args'] = ['-t', '600']
                
                # éŸ³å£°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ
                ydl.download([url])
            
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
            if os.path.exists(audio_file):
                file_size = os.path.getsize(audio_file)
                print(f"âœ… éŸ³å£°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {audio_file} ({file_size} bytes)")
                return audio_file
            else:
                print(f"âŒ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {audio_file}")
                return None
                
        except Exception as e:
            print(f"âŒ YouTubeéŸ³å£°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def transcribe_audio_with_whisper(self, audio_file_path):
        """OpenAI WhisperAPIã§éŸ³å£°ã‚’å­—å¹•åŒ–"""
        try:
            print(f"ğŸ¤ WhisperéŸ³å£°å­—å¹•åŒ–é–‹å§‹: {audio_file_path}")
            
            if not self.openai_available:
                print("âŒ OpenAI APIåˆ©ç”¨ä¸å¯")
                return None
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ï¼ˆWhisperAPIã¯25MBåˆ¶é™ï¼‰
            file_size = os.path.getsize(audio_file_path)
            if file_size > 25 * 1024 * 1024:  # 25MB
                print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã™ãã¾ã™: {file_size} bytes")
                # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†å‰²ã™ã‚‹å‡¦ç†ã‚’å®Ÿè£…å¯èƒ½
                return None
            
            # Whisper APIã‚’å‘¼ã³å‡ºã—
            with open(audio_file_path, 'rb') as audio_file:
                transcript = self.openai_client.audio.transcriptions.create(
                    model=self.whisper_settings['model'],
                    file=audio_file,
                    response_format=self.whisper_settings['response_format'],
                    language=self.whisper_settings['language'],
                    temperature=self.whisper_settings['temperature']
                )
            
            if transcript and hasattr(transcript, 'text'):
                transcript_text = transcript.text
            else:
                transcript_text = str(transcript)
            
            print(f"âœ… Whisperå­—å¹•åŒ–å®Œäº†: {len(transcript_text)}æ–‡å­—")
            print(f"ğŸ“ å­—å¹•ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: {transcript_text[:200]}...")
            
            return transcript_text
            
        except Exception as e:
            print(f"âŒ Whisperå­—å¹•åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def summarize_transcript(self, transcript):
        """ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’è¦ç´„"""
        try:
            print(f"ğŸ“„ ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆè¦ç´„é–‹å§‹: {len(transcript)}æ–‡å­—")
            
            if not self.openai_available:
                print("âŒ OpenAI APIåˆ©ç”¨ä¸å¯")
                return None
            
            # é•·ã„ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
            if len(transcript) > self.summary_settings['max_transcript_length']:
                print("ğŸ“š é•·æ–‡ã®ãŸã‚åˆ†å‰²è¦ç´„ã‚’å®Ÿè¡Œ")
                return self.summarize_long_transcript(transcript)
            
            # è¦ç´„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            summary_prompt = f"""
ä»¥ä¸‹ã¯æ•™è‚²å‹•ç”»ã®éŸ³å£°ã‚’å­—å¹•åŒ–ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚
ã“ã®å†…å®¹ã‚’å­¦ç¿’è€…å‘ã‘ã«åˆ†ã‹ã‚Šã‚„ã™ãè¦ç´„ã—ã¦ãã ã•ã„ã€‚

è¦ç´„ã®ãƒã‚¤ãƒ³ãƒˆ:
1. ä¸»è¦ãªå­¦ç¿’ãƒã‚¤ãƒ³ãƒˆã‚’æŠ½å‡º
2. é‡è¦ãªæ¦‚å¿µã‚„ç”¨èªã‚’å«ã‚ã‚‹
3. å…·ä½“ä¾‹ãŒã‚ã‚Œã°å«ã‚ã‚‹
4. å­¦ç¿’è€…ãŒç†è§£ã—ã‚„ã™ã„æ§‹é€ ã§æ•´ç†
5. 400-600æ–‡å­—ç¨‹åº¦ã§ç°¡æ½”ã«

å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆ:
{transcript}

è¦ç´„:
"""
            
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": "ã‚ãªãŸã¯æ•™è‚²ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è¦ç´„ã®å°‚é–€å®¶ã§ã™ã€‚å­¦ç¿’è€…ãŒç†è§£ã—ã‚„ã™ã„è¦ç´„ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
                    },
                    {
                        "role": "user",
                        "content": summary_prompt
                    }
                ],
                max_tokens=self.summary_settings['summary_max_tokens'],
                temperature=0.3
            )
            
            summary = response.choices[0].message.content.strip()
            
            print(f"âœ… è¦ç´„å®Œäº†: {len(summary)}æ–‡å­—")
            print(f"ğŸ“‹ è¦ç´„ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: {summary[:200]}...")
            
            return summary
            
        except Exception as e:
            print(f"âŒ è¦ç´„å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def summarize_long_transcript(self, transcript):
        """é•·ã„ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®åˆ†å‰²è¦ç´„"""
        try:
            print("ğŸ“š é•·æ–‡ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®åˆ†å‰²è¦ç´„é–‹å§‹")
            
            # ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
            chunks = self.split_text_into_chunks(
                transcript, 
                self.summary_settings['chunk_size'],
                self.summary_settings['overlap_size']
            )
            
            print(f"ğŸ“„ {len(chunks)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²")
            
            # å„ãƒãƒ£ãƒ³ã‚¯ã‚’è¦ç´„
            chunk_summaries = []
            for i, chunk in enumerate(chunks):
                print(f"ğŸ“ ãƒãƒ£ãƒ³ã‚¯{i+1}/{len(chunks)}ã‚’è¦ç´„ä¸­...")
                
                chunk_summary = self.summarize_single_chunk(chunk, i+1)
                if chunk_summary:
                    chunk_summaries.append(chunk_summary)
            
            # ãƒãƒ£ãƒ³ã‚¯è¦ç´„ã‚’çµ±åˆ
            if chunk_summaries:
                final_summary = self.combine_chunk_summaries(chunk_summaries)
                print(f"âœ… åˆ†å‰²è¦ç´„å®Œäº†: {len(final_summary)}æ–‡å­—")
                return final_summary
            else:
                print("âŒ ãƒãƒ£ãƒ³ã‚¯è¦ç´„ã«å¤±æ•—")
                return None
                
        except Exception as e:
            print(f"âŒ åˆ†å‰²è¦ç´„ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def split_text_into_chunks(self, text, chunk_size, overlap_size):
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ä»˜ãã§ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²"""
        chunks = []
        start = 0
        
        while start < len(text):
            end = start + chunk_size
            
            # æ–‡ã®å¢ƒç•Œã§åˆ‡ã‚‹
            if end < len(text):
                # æœ€å¾Œã®å¥ç‚¹ã‚’æ¢ã™
                last_period = text.rfind('ã€‚', start, end)
                if last_period > start:
                    end = last_period + 1
            
            chunk = text[start:end]
            chunks.append(chunk)
            
            # ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã‚’è€ƒæ…®ã—ã¦æ¬¡ã®é–‹å§‹ä½ç½®ã‚’è¨­å®š
            start = end - overlap_size
            if start >= len(text):
                break
        
        return chunks

    def summarize_single_chunk(self, chunk, chunk_number):
        """å˜ä¸€ãƒãƒ£ãƒ³ã‚¯ã®è¦ç´„"""
        try:
            prompt = f"""
ä»¥ä¸‹ã¯æ•™è‚²å‹•ç”»ã®ä¸€éƒ¨(ãƒ‘ãƒ¼ãƒˆ{chunk_number})ã®éŸ³å£°ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚
ã“ã®éƒ¨åˆ†ã®è¦ç‚¹ã‚’200æ–‡å­—ç¨‹åº¦ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚

ãƒ†ã‚­ã‚¹ãƒˆ:
{chunk}

è¦ç´„:
"""
            
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "user", "content": prompt}
                ],
                max_tokens=300,
                temperature=0.3
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"âŒ ãƒãƒ£ãƒ³ã‚¯{chunk_number}è¦ç´„ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def combine_chunk_summaries(self, chunk_summaries):
        """ãƒãƒ£ãƒ³ã‚¯è¦ç´„ã‚’çµ±åˆã—ã¦æœ€çµ‚è¦ç´„ã‚’ä½œæˆ"""
        try:
            combined_text = "\n\n".join([f"ãƒ‘ãƒ¼ãƒˆ{i+1}: {summary}" for i, summary in enumerate(chunk_summaries)])
            
            final_prompt = f"""
ä»¥ä¸‹ã¯æ•™è‚²å‹•ç”»ã®å„ãƒ‘ãƒ¼ãƒˆã®è¦ç´„ã§ã™ã€‚
ã“ã‚Œã‚‰ã‚’çµ±åˆã—ã¦ã€å‹•ç”»å…¨ä½“ã®å­¦ç¿’å†…å®¹ã‚’åŒ…æ‹¬çš„ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚

å„ãƒ‘ãƒ¼ãƒˆã®è¦ç´„:
{combined_text}

æœ€çµ‚çš„ãªçµ±åˆè¦ç´„(500-800æ–‡å­—):
"""
            
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": "ã‚ãªãŸã¯æ•™è‚²ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è¦ç´„çµ±åˆã®å°‚é–€å®¶ã§ã™ã€‚"
                    },
                    {
                        "role": "user",
                        "content": final_prompt
                    }
                ],
                max_tokens=1000,
                temperature=0.3
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"âŒ è¦ç´„çµ±åˆã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def generate_quiz_from_summary(self, video_title, summary, user=None):
        """è¦ç´„ã‹ã‚‰ã‚¯ã‚¤ã‚ºã‚’ç”Ÿæˆ"""
        try:
            print(f"ğŸ“ è¦ç´„ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¤ã‚ºç”Ÿæˆé–‹å§‹")
            
            if not self.openai_available:
                print("âŒ OpenAI APIåˆ©ç”¨ä¸å¯")
                return None
            
            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æ
            content_type = self.detect_content_type(video_title)
            age_group = self.detect_age_group(video_title, user)
            
            print(f"ğŸ“Š åˆ†æçµæœ: {content_type} - {age_group}")
            
            # è¦ç´„ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¤ã‚ºç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            quiz_prompt = self.build_summary_based_quiz_prompt(
                video_title, summary, content_type, age_group
            )
            
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": f"ã‚ãªãŸã¯{age_group}å‘ã‘ã®æ•™è‚²ã‚¯ã‚¤ã‚ºä½œæˆã®å°‚é–€å®¶ã§ã™ã€‚å‹•ç”»ã®è¦ç´„ã‹ã‚‰é©åˆ‡ãªå­¦ç¿’ã‚¯ã‚¤ã‚ºã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
                    },
                    {
                        "role": "user",
                        "content": quiz_prompt
                    }
                ],
                max_tokens=2500,
                temperature=0.7,
                response_format={"type": "json_object"}
            )
            
            quiz_json = response.choices[0].message.content
            quiz_data = json.loads(quiz_json)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
            quiz_data.update({
                'generation_method': 'summary_based',
                'content_type': content_type,
                'age_group': age_group,
                'video_title': video_title,
                'source_summary': summary[:200] + "..." if len(summary) > 200 else summary
            })
            
            if self.validate_quiz_structure(quiz_data):
                print(f"âœ… è¦ç´„ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¤ã‚ºç”Ÿæˆå®Œäº†: {len(quiz_data.get('questions', []))}å•")
                return quiz_data
            else:
                print("âŒ ç”Ÿæˆã•ã‚ŒãŸã‚¯ã‚¤ã‚ºæ§‹é€ ãŒç„¡åŠ¹")
                return None
                
        except Exception as e:
            print(f"âŒ è¦ç´„ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¤ã‚ºç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def build_summary_based_quiz_prompt(self, video_title, summary, content_type, age_group):
        """è¦ç´„ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¤ã‚ºç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰"""
        age_descriptions = {
            'elementary_low': 'å°å­¦1-3å¹´',
            'elementary_mid': 'å°å­¦4-6å¹´', 
            'junior_high': 'ä¸­å­¦ç”Ÿ',
            'general': 'ä¸€èˆ¬'
        }
        
        age_desc = age_descriptions.get(age_group, 'ä¸€èˆ¬')
        
        return f"""
å‹•ç”»ã€Œ{video_title}ã€ã®å†…å®¹è¦ç´„ã‹ã‚‰ã€{age_desc}å‘ã‘ã®{content_type}åˆ†é‡ã®ã‚¯ã‚¤ã‚ºã‚’5å•ä½œæˆã—ã¦ãã ã•ã„ã€‚

å‹•ç”»å†…å®¹ã®è¦ç´„:
{summary}

ä»¥ä¸‹ã®JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
{{
    "questions": [
        {{
            "question": "å‹•ç”»å†…å®¹ã«åŸºã¥ãå•é¡Œæ–‡",
            "options": ["é¸æŠè‚¢1", "é¸æŠè‚¢2", "é¸æŠè‚¢3", "é¸æŠè‚¢4"],
            "correct": 2,
            "explanation": "å‹•ç”»å†…å®¹ã‚’å‚ç…§ã—ãŸè©³ã—ã„è§£èª¬",
            "content_reference": "è¦ç´„ã®ã©ã®éƒ¨åˆ†ã«åŸºã¥ã„ã¦ã„ã‚‹ã‹"
        }}
    ]
}}

è¦ä»¶:
- å‹•ç”»ã®å®Ÿéš›ã®å†…å®¹ã«åŸºã¥ãå•é¡Œã®ã¿ä½œæˆ
- ä¸€èˆ¬è«–ã§ã¯ãªãã€ã“ã®å‹•ç”»ç‰¹æœ‰ã®å†…å®¹ã‚’å•ã†
- {age_desc}ã«é©ã—ãŸé›£æ˜“åº¦ã¨è¡¨ç¾
- 4æŠå•é¡Œã§æ­£è§£ã¯1-4ã®æ•°å­—
- è§£èª¬ã¯å‹•ç”»å†…å®¹ã‚’å‚ç…§
- å­¦ç¿’åŠ¹æœã®é«˜ã„è‰¯è³ªãªå•é¡Œ
"""

    def cleanup_temp_file(self, file_path):
        """ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤"""
        try:
            if file_path and os.path.exists(file_path):
                os.remove(file_path)
                print(f"ğŸ—‘ï¸ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤: {file_path}")
        except Exception as e:
            print(f"âš ï¸ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")

    def generate_quiz(self, video_id, user=None, force_fallback=False, use_whisper=True):
        """å‹•ç”»IDã‹ã‚‰ã‚¯ã‚¤ã‚ºã‚’è‡ªå‹•ç”Ÿæˆï¼ˆWhisperãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¯¾å¿œç‰ˆï¼‰"""
        try:
            # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¼·åˆ¶å®Ÿè¡Œ
            if force_fallback or self.debug_settings.get('force_fallback', False):
                print("ğŸ”§ ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”Ÿæˆã‚’å¼·åˆ¶å®Ÿè¡Œ")
                return self.execute_fallback_generation(video_id, user)
            
            from django.apps import apps
            
            try:
                LearningVideo = apps.get_model('playlist', 'LearningVideo')
                video = LearningVideo.objects.get(id=video_id)
                
                print(f"ğŸ¤– AIã‚¯ã‚¤ã‚ºç”Ÿæˆé–‹å§‹: ID={video_id}, ã‚¿ã‚¤ãƒˆãƒ«={video.title}")
                
                # Whisperãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ä½¿ç”¨åˆ¤å®š
                if use_whisper and self.openai_available and self.should_use_whisper_pipeline(video):
                    print("ğŸµ Whisperãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ç”¨ã—ã¾ã™")
                    return self.generate_quiz_with_whisper_pipeline(video_id, user)
                else:
                    print("ğŸ“‹ å¾“æ¥ã®ã‚¿ã‚¤ãƒˆãƒ«ãƒ™ãƒ¼ã‚¹ç”Ÿæˆã‚’ä½¿ç”¨ã—ã¾ã™")
                    return self.generate_quiz_title_based(video, user)
                
            except Exception as model_error:
                print(f"âŒ ãƒ¢ãƒ‡ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼: {model_error}")
                return self.execute_fallback_generation(video_id, user, error_message=str(model_error))
            
        except Exception as e:
            print(f"âŒ ã‚¯ã‚¤ã‚ºç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return self.execute_fallback_generation(video_id, user, error_message=str(e))

    def should_use_whisper_pipeline(self, video):
        """Whisperãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ç”¨ã™ã¹ãã‹ã®åˆ¤å®š"""
        try:
            # YouTube APIã§å‹•ç”»ã®è©³ç´°æƒ…å ±ã‚’å–å¾—
            if not self.youtube_api_key:
                print("âš ï¸ YouTube APIæœªè¨­å®š - ã‚¿ã‚¤ãƒˆãƒ«ãƒ™ãƒ¼ã‚¹ç”Ÿæˆã‚’ä½¿ç”¨")
                return False
            
            url = f"https://www.googleapis.com/youtube/v3/videos"
            params = {
                'part': 'contentDetails,snippet',
                'id': video.video_id,
                'key': self.youtube_api_key
            }
            
            response = requests.get(url, params=params, timeout=10)
            if response.status_code == 200:
                data = response.json()
                if data.get('items'):
                    item = data['items'][0]
                    
                    # å‹•ç”»ã®é•·ã•ã‚’ãƒã‚§ãƒƒã‚¯
                    duration = item.get('contentDetails', {}).get('duration', '')
                    duration_seconds = self.parse_youtube_duration(duration)
                    
                    # 20åˆ†ä»¥ä¸‹ã®å‹•ç”»ã®ã¿Whisperãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ç”¨
                    if duration_seconds and duration_seconds <= 1200:  # 20åˆ†
                        print(f"âœ… Whisperãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¯¾è±¡: {duration_seconds}ç§’")
                        return True
                    else:
                        print(f"âš ï¸ å‹•ç”»ãŒé•·ã™ãã¾ã™: {duration_seconds}ç§’ - ã‚¿ã‚¤ãƒˆãƒ«ãƒ™ãƒ¼ã‚¹ç”Ÿæˆã‚’ä½¿ç”¨")
                        return False
            
            print("âš ï¸ YouTube APIå¿œç­”ã‚¨ãƒ©ãƒ¼ - ã‚¿ã‚¤ãƒˆãƒ«ãƒ™ãƒ¼ã‚¹ç”Ÿæˆã‚’ä½¿ç”¨")
            return False
            
        except Exception as e:
            print(f"âš ï¸ Whisperãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆ¤å®šã‚¨ãƒ©ãƒ¼: {e} - ã‚¿ã‚¤ãƒˆãƒ«ãƒ™ãƒ¼ã‚¹ç”Ÿæˆã‚’ä½¿ç”¨")
            return False

    def parse_youtube_duration(self, duration_str):
        """YouTube durationæ–‡å­—åˆ—ã‚’ç§’ã«å¤‰æ›"""
        try:
            import re
            # PT1H2M30S -> 3750ç§’ã®å¤‰æ›
            pattern = r'PT(?:(\d+)H)?(?:(\d+)M)?(?:(\d+)S)?'
            match = re.match(pattern, duration_str)
            
            if match:
                hours = int(match.group(1) or 0)
                minutes = int(match.group(2) or 0)
                seconds = int(match.group(3) or 0)
                
                total_seconds = hours * 3600 + minutes * 60 + seconds
                return total_seconds
            
            return None
            
        except Exception as e:
            print(f"âŒ durationè§£æã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def generate_quiz_title_based(self, video, user):
        """å¾“æ¥ã®ã‚¿ã‚¤ãƒˆãƒ«ãƒ™ãƒ¼ã‚¹ç”Ÿæˆ"""
        print("ğŸ“‹ ã‚¿ã‚¤ãƒˆãƒ«ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¤ã‚ºç”Ÿæˆ")
        
        content_type = self.detect_content_type(video.title)
        age_group = self.detect_age_group(video.title, user)
        
        # æ—¢å­˜ã®AIç”Ÿæˆã‚’è©¦è¡Œ
        ai_result = self.try_ai_generation_sync(video.title, content_type, age_group)
        if ai_result and ai_result.get('questions'):
            ai_result['generation_method'] = 'title_based'
            return ai_result
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«ç§»è¡Œ
        return self.execute_fallback_generation(video.id, user)
